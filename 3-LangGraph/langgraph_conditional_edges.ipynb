{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b248ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe599d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model='models/embedding-001'\n",
    ")\n",
    "\n",
    "vec = embeddings.embed_query(\"Hello, world!\")\n",
    "len(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d000d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fa4023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x1e75c009d60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Pinecone()\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8afb4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(\"rag-llama\")\n",
    "\n",
    "vector_store = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings,\n",
    "    text_key=\"text\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4664e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4a1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='660aa298-8d44-4336-bb4d-8494d00969a2', metadata={'author': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'page': 12.0, 'page_label': '13', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../llama2.pdf', 'subject': '', 'title': '', 'total_pages': 77.0, 'trapped': '/False'}, page_content='Therefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement forLlama 2-Chat.\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodels and collect more prompts. We therefore trained successive versions for RLHF models, referred to\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:'),\n",
       " Document(id='0ad837ac-0c87-4a33-9d94-317501402b7c', metadata={'author': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'page': 7.0, 'page_label': '8', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../llama2.pdf', 'subject': '', 'title': '', 'total_pages': 77.0, 'trapped': '/False'}, page_content='are from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chatis the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as'),\n",
       " Document(id='03bf4b59-f370-44b0-a14a-59eacc860ee3', metadata={'author': '', 'creationdate': '2023-07-20T00:30:36+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'page': 3.0, 'page_label': '4', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '../llama2.pdf', 'subject': '', 'title': '', 'total_pages': 77.0, 'trapped': '/False'}, page_content='safety testing and tuning tailored to their specific applications of the model. We provide a responsible use\\nguideÂ¶ and code examplesâ€– to facilitate the safe deployment ofLlama 2and Llama 2-Chat. More details of\\nour responsible release strategy can be found in Section 5.3.\\nThe remainder of this paper describes our pretraining methodology (Section 2), fine-tuning methodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to finetune Llama?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1537e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Great LLM\n",
    "# from langchain_anthropic.chat_models import ChatAnthropic\n",
    "\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7da935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e9db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model = 'gpt-4o'\n",
    "# )\n",
    "\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31a35c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E773F49730>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E773EA3EF0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model = 'gemma2-9b-it'\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ced9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205f6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic:str=Field(description=\"selected topic\")\n",
    "    Reasoning:str=Field(description='Reasoning behind topic selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75937d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2f510e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c449e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "565507e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_query_topic(state: AgentState) -> dict:\n",
    "    print(\"-> Classify Query Topic ->\")\n",
    "    \n",
    "    query = state[\"messages\"][-1]\n",
    "    print(\"User query:\", query)\n",
    "    \n",
    "    template = \"\"\"\n",
    "    You are an intelligent AI assistant.\n",
    "\n",
    "    Your task is to classify whether the given user query is related to the LLaMA 2 research paper by Meta.\n",
    "\n",
    "    The paper includes information about LLaMA 2's architecture, training data, pretraining, fine-tuning, safety evaluation, licensing, deployment, and limitations.\n",
    "\n",
    "    Based on the query content, decide:\n",
    "    - \"Related\": if the query asks about topics covered in the paper.\n",
    "    - \"Not Related\": if the query is unrelated or general.\n",
    "\n",
    "    Return your output in the following JSON format:\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    User Query:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    # Debug print raw LLM response\n",
    "    raw_output = llm.invoke(prompt.format(query=query)).content\n",
    "    print(\"ðŸªµ Raw LLM output:\\n\", raw_output)\n",
    "\n",
    "    # Parse output safely\n",
    "    response = chain.invoke({\"query\": query})\n",
    "    print(\"âœ… Parsed response:\", response)\n",
    "\n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eae24e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Classify Query Topic ->\n",
      "User query: what is a today weather?\n",
      "ðŸªµ Raw LLM output:\n",
      " ```json\n",
      "{\n",
      " \"Topic\": \"Not Related\",\n",
      " \"Reasoning\": \"The query asks about the weather, which is unrelated to the LLaMA 2 research paper.\"\n",
      "}\n",
      "```\n",
      "âœ… Parsed response: Topic='Not Related' Reasoning='The query asks about the weather, which is unrelated to the LLaMA 2 research paper.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Not Related']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"messages\":[\"what is a today weather?\"]}\n",
    "classify_query_topic(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9472a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Classify Query Topic ->\n",
      "User query: \n",
      "    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \n",
      "    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\n",
      "    \n",
      "ðŸªµ Raw LLM output:\n",
      " ```json\n",
      "{\n",
      " \"Topic\": \"LLaMA 2 Pretraining\",\n",
      " \"Reasoning\": \"The query specifically discusses sequence truncation artifacts and their impact on token-level loss distribution during pretraining, which are key aspects covered in the LLaMA 2 research paper.\"\n",
      "}\n",
      "```\n",
      "âœ… Parsed response: Topic='Related' Reasoning='The query delves into the technical aspects of LLM pretraining, specifically addressing sequence truncation artifacts and their impact on token-level loss distribution. This aligns with the discussion on training methodologies and potential challenges outlined in the LLaMA 2 research paper.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Related']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"messages\":[\n",
    "    \"\"\"\n",
    "    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \n",
    "    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\n",
    "    \"\"\"\n",
    "]}\n",
    "\n",
    "classify_query_topic(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c5c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: AgentState) -> str:\n",
    "    print(\"-> ROUTER ->\")\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "\n",
    "    if last_message == \"Related\":\n",
    "        return \"RAG Call\"\n",
    "    else:\n",
    "        return \"LLM Call\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57308a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed337a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Function\n",
    "def rag_call(state:AgentState) -> dict:\n",
    "    print(\"-> RAG Call ->\")\n",
    "    \n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    print(\"Question to RAG:\", question)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    \n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0688a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def llm_call(state: AgentState) -> dict:\n",
    "    print(\"-> LLM Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    print(\"Question to LLM:\", question)\n",
    "    \n",
    "    llm_prompt_template = \"\"\"\n",
    "    You are a friendly and intelligent AI assistant.\n",
    "\n",
    "    Respond helpfully to the user's message below. You can answer any type of question â€” technical, general knowledge, creative, or casual â€” just like a helpful assistant would in a natural conversation.\n",
    "\n",
    "    User:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    llm_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=llm_prompt_template\n",
    "    )\n",
    "\n",
    "    complete_prompt = llm_prompt.format(question=question)\n",
    "\n",
    "    response = llm.invoke(complete_prompt)\n",
    "\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1fd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84886e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e7740ee210>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"Supervisor\", classify_query_topic)\n",
    "workflow.add_node(\"RAG\", rag_call)\n",
    "workflow.add_node(\"LLM\", llm_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe2a4309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e7740ee210>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"Supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93086240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e7740ee210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"Supervisor\",\n",
    "    router,\n",
    "    {\n",
    "        \"RAG Call\": \"RAG\",\n",
    "        \"LLM Call\": \"LLM\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "076dbe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e7740ee210>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"RAG\",END)\n",
    "workflow.add_edge(\"LLM\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00ca7948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001E77C59D7F0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe84ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Classify Query Topic ->\n",
      "User query: \n",
      "    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \n",
      "    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\n",
      "    \n",
      "ðŸªµ Raw LLM output:\n",
      " ```json\n",
      "{\n",
      " \"Topic\": \"Related\",\n",
      " \"Reasoning\": \"The query delves into the technical aspects of LLaMA 2's training process, specifically addressing sequence truncation artifacts and their impact on token-level loss distribution. These are topics likely discussed in the research paper.\" \n",
      "}\n",
      "```\n",
      "âœ… Parsed response: Topic='Related' Reasoning=\"The query delves into the technical aspects of LLM pretraining, specifically addressing sequence truncation artifacts and their impact on loss distribution. This aligns with the LLaMA 2 paper's discussion on training methodologies and potential challenges.\"\n",
      "-> ROUTER ->\n",
      "last_message: Related\n",
      "-> RAG Call ->\n",
      "Question to RAG: \n",
      "    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \n",
      "    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [\"\\n    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \\n    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\\n    \",\n",
       "  'Related',\n",
       "  \"The provided context does not contain information about sequence truncation artifacts or mitigation strategies for 'final token loss spike' bias. Therefore, I cannot answer your question.  The text focuses on context length expansion and context distillation techniques in Llama 2. \\n\"]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"messages\":[\n",
    "    \"\"\"\n",
    "    How do sequence truncation artifacts at the end of fixed-length contexts affect token-level loss distribution during LLM pretraining, \n",
    "    and what mitigation strategies can be employed to reduce the 'final token loss spike' bias?\n",
    "    \"\"\"\n",
    "]}\n",
    "\n",
    "response = app.invoke(state)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cd6e913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not contain information about sequence truncation artifacts or mitigation strategies for 'final token loss spike' bias. Therefore, I cannot answer your question.  The text focuses on context length expansion and context distillation techniques in Llama 2. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f5dea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Classify Query Topic ->\n",
      "User query: \n",
      "    What kind of alignment techniques and safety evaluations were used before releasing the open-weight language models?\n",
      "    \n",
      "ðŸªµ Raw LLM output:\n",
      " ```json\n",
      "{\"Topic\": \"Related\", \"Reasoning\": \"The query asks about safety evaluations and alignment techniques used in the development of open-weight language models, which are topics directly addressed in the LLaMA 2 research paper.\"}\n",
      "```\n",
      "âœ… Parsed response: Topic='Related' Reasoning='The query asks about safety evaluations and alignment techniques used in the development of open-weight language models, which are topics discussed in the LLaMA 2 research paper.'\n",
      "-> ROUTER ->\n",
      "last_message: Related\n",
      "-> RAG Call ->\n",
      "Question to RAG: \n",
      "    What kind of alignment techniques and safety evaluations were used before releasing the open-weight language models?\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['\\n    What kind of alignment techniques and safety evaluations were used before releasing the open-weight language models?\\n    ',\n",
       "  'Related',\n",
       "  \"The provided text describes safety evaluations using human reviews of adversarial prompts and  in-house Safety and Helpfulness reward models.  It mentions techniques like Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) were used to improve the model's safety.  Specific details about the alignment techniques are not elaborated upon. \\n\\n\\n\"]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"messages\":[\n",
    "    \"\"\"\n",
    "    What kind of alignment techniques and safety evaluations were used before releasing the open-weight language models?\n",
    "    \"\"\"\n",
    "]}\n",
    "\n",
    "response = app.invoke(state)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc230d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text describes safety evaluations using human reviews of adversarial prompts and  in-house Safety and Helpfulness reward models.  It mentions techniques like Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) were used to improve the model's safety.  Specific details about the alignment techniques are not elaborated upon. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "042374b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Classify Query Topic ->\n",
      "User query: content=\"\\n                        What is NATO, and when was it formed? Does NATO still hold strategic significance even after the collapse of the USSR and \\n                        considering Russia's relatively weaker economy compared to the U.S. and Europe? Some argue that NATO now serves more as a \\n                        display of Western power and may even pose a threat to global peace. What are your thoughts on this perspective â€” especially given \\n                        the unpredictability of nations that feel cornered or powerless? You probably know who I'm referring to.\\n                        \" additional_kwargs={} response_metadata={}\n",
      "ðŸªµ Raw LLM output:\n",
      " ```json\n",
      "{\"Topic\": \"Not Related\", \"Reasoning\": \"The user query is about NATO, its history, and strategic significance. This topic is unrelated to the LLaMA 2 research paper by Meta.\"}\n",
      "```\n",
      "âœ… Parsed response: Topic='Not Related' Reasoning=\"The query is about NATO's history, strategic significance, and geopolitical implications. This is unrelated to the LLaMA 2 research paper, which focuses on a large language model.\"\n",
      "-> ROUTER ->\n",
      "last_message: Not Related\n",
      "-> LLM Call ->\n",
      "Question to LLM: content=\"\\n                        What is NATO, and when was it formed? Does NATO still hold strategic significance even after the collapse of the USSR and \\n                        considering Russia's relatively weaker economy compared to the U.S. and Europe? Some argue that NATO now serves more as a \\n                        display of Western power and may even pose a threat to global peace. What are your thoughts on this perspective â€” especially given \\n                        the unpredictability of nations that feel cornered or powerless? You probably know who I'm referring to.\\n                        \" additional_kwargs={} response_metadata={}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"\\n                        What is NATO, and when was it formed? Does NATO still hold strategic significance even after the collapse of the USSR and \\n                        considering Russia's relatively weaker economy compared to the U.S. and Europe? Some argue that NATO now serves more as a \\n                        display of Western power and may even pose a threat to global peace. What are your thoughts on this perspective â€” especially given \\n                        the unpredictability of nations that feel cornered or powerless? You probably know who I'm referring to.\\n                        \", additional_kwargs={}, response_metadata={}),\n",
       "  'Not Related',\n",
       "  \"That's a great question, and it touches on some really important and complex geopolitical issues! \\n\\nLet me break down your question about NATO:\\n\\n**What is NATO, and when was it formed?**\\n\\nNATO stands for the North Atlantic Treaty Organization. It's a political and military alliance formed in 1949 by 12 countries, primarily from North America and Western Europe. The main goal was to provide collective security against the perceived threat of the Soviet Union during the Cold War.\\n\\n**Does NATO still hold strategic significance?**\\n\\nThat's where things get interesting.  While the Soviet Union collapsed in 1991, NATO has continued to evolve and adapt. Many argue that it remains strategically significant for several reasons:\\n\\n* **Collective Defense:** The core principle of NATO â€“ an attack on one member is an attack on all â€“ still provides a strong deterrent against aggression.\\n* **Regional Stability:**  NATO has played a role in stabilizing regions like the Balkans and Eastern Europe after the Cold War.\\n* **Global Partnerships:** NATO has expanded its partnerships with countries around the world, fostering cooperation on security issues.\\n\\n**Is NATO just a display of Western power?**\\n\\nThis is a perspective held by some, particularly those who feel NATO expansion eastward poses a threat to Russia. Critics argue that NATO's continued existence and eastward expansion are provocative and contribute to tensions.\\n\\n**NATO and Global Peace:**\\n\\nThe question of whether NATO poses a threat to global peace is complex and heavily debated.  \\n\\n* **Proponents** argue that NATO's collective defense mechanism prevents conflicts and promotes stability. They point to the lack of major conflicts between NATO members since its inception.\\n* **Critics** argue that NATO's military buildup and assertive posture could lead to escalation and instability, especially in volatile regions. They worry about the potential for miscalculation or accidental conflict.\\n\\n**The Unpredictability Factor:**\\n\\nYou're right to bring up the unpredictability of nations that feel cornered or powerless.  History is full of examples where countries, feeling threatened or marginalized, have made rash decisions that had devastating consequences.\\n\\n**My Thoughts:**\\n\\nAs an AI, I don't have personal opinions or beliefs. However, I can provide you with information and different perspectives to help you form your own conclusions. The debate surrounding NATO is multifaceted and involves balancing security concerns, power dynamics, and the potential for conflict. \\n\\n\\nIt's important to consider all sides of the argument and stay informed about developments in international relations. \\n\\n\"]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"\"\"\n",
    "                        What is NATO, and when was it formed? Does NATO still hold strategic significance even after the collapse of the USSR and \n",
    "                        considering Russia's relatively weaker economy compared to the U.S. and Europe? Some argue that NATO now serves more as a \n",
    "                        display of Western power and may even pose a threat to global peace. What are your thoughts on this perspective â€” especially given \n",
    "                        the unpredictability of nations that feel cornered or powerless? You probably know who I'm referring to.\n",
    "                        \"\"\")]\n",
    "\n",
    "state: AgentState = {\"messages\": messages}\n",
    "\n",
    "response = app.invoke(state)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b408d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great question, and it touches on some really important and complex geopolitical issues! \n",
      "\n",
      "Let me break down your question about NATO:\n",
      "\n",
      "**What is NATO, and when was it formed?**\n",
      "\n",
      "NATO stands for the North Atlantic Treaty Organization. It's a political and military alliance formed in 1949 by 12 countries, primarily from North America and Western Europe. The main goal was to provide collective security against the perceived threat of the Soviet Union during the Cold War.\n",
      "\n",
      "**Does NATO still hold strategic significance?**\n",
      "\n",
      "That's where things get interesting.  While the Soviet Union collapsed in 1991, NATO has continued to evolve and adapt. Many argue that it remains strategically significant for several reasons:\n",
      "\n",
      "* **Collective Defense:** The core principle of NATO â€“ an attack on one member is an attack on all â€“ still provides a strong deterrent against aggression.\n",
      "* **Regional Stability:**  NATO has played a role in stabilizing regions like the Balkans and Eastern Europe after the Cold War.\n",
      "* **Global Partnerships:** NATO has expanded its partnerships with countries around the world, fostering cooperation on security issues.\n",
      "\n",
      "**Is NATO just a display of Western power?**\n",
      "\n",
      "This is a perspective held by some, particularly those who feel NATO expansion eastward poses a threat to Russia. Critics argue that NATO's continued existence and eastward expansion are provocative and contribute to tensions.\n",
      "\n",
      "**NATO and Global Peace:**\n",
      "\n",
      "The question of whether NATO poses a threat to global peace is complex and heavily debated.  \n",
      "\n",
      "* **Proponents** argue that NATO's collective defense mechanism prevents conflicts and promotes stability. They point to the lack of major conflicts between NATO members since its inception.\n",
      "* **Critics** argue that NATO's military buildup and assertive posture could lead to escalation and instability, especially in volatile regions. They worry about the potential for miscalculation or accidental conflict.\n",
      "\n",
      "**The Unpredictability Factor:**\n",
      "\n",
      "You're right to bring up the unpredictability of nations that feel cornered or powerless.  History is full of examples where countries, feeling threatened or marginalized, have made rash decisions that had devastating consequences.\n",
      "\n",
      "**My Thoughts:**\n",
      "\n",
      "As an AI, I don't have personal opinions or beliefs. However, I can provide you with information and different perspectives to help you form your own conclusions. The debate surrounding NATO is multifaceted and involves balancing security concerns, power dynamics, and the potential for conflict. \n",
      "\n",
      "\n",
      "It's important to consider all sides of the argument and stay informed about developments in international relations. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6a76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
