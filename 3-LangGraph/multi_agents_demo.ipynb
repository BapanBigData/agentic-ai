{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277b58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7572a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dfb91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BpJxMwEdx7eQFpDAdY7m4mGMI5PU8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1dbacedd-ab38-4fa2-9e2e-5a6da77b92dd-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cb1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(state):\n",
    "    result = state[\"num1\"] + state[\"num2\"]\n",
    "    print(f\"addition is {result}\")\n",
    "    \n",
    "    return Command(goto=\"multiply\", update={\"sum\":result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cf1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition is 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 30}, goto='multiply')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"num1\":10,\"num2\":20}\n",
    "\n",
    "add_number(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccc8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1771bf1a",
   "metadata": {},
   "source": [
    "#### **Dummy Multi-Agent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2168decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c95a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for agent communication\n",
    "@tool\n",
    "def transfer_to_multiplication_expert() -> str:\n",
    "    \"\"\"Transfer the query to the multiplication expert for precise calculations.\"\"\"\n",
    "    return \"This question involves multiplication. Please handle it using the multiplication expert agent.\"\n",
    "\n",
    "@tool\n",
    "def transfer_to_addition_expert() -> str:\n",
    "    \"\"\"Transfer the query to the addition expert for summation-related help.\"\"\"\n",
    "    return \"This question involves addition. Please route it to the addition expert agent.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816b42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools([transfer_to_addition_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acea8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tool.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9e6049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfa87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tool.invoke(\"what is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a945de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e6b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_addition_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_Ck7IvPiA5ETYYugeEhgjsvEX',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5efdc7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ck7IvPiA5ETYYugeEhgjsvEX', 'function': {'arguments': '{}', 'name': 'transfer_to_addition_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BpJxPj1o493lKnoiJbF69GZtt2M7M', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7835cbdd-35eb-40d0-9e07-2f4779914404-0', tool_calls=[{'name': 'transfer_to_addition_expert', 'args': {}, 'id': 'call_Ck7IvPiA5ETYYugeEhgjsvEX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9560c2e",
   "metadata": {},
   "source": [
    "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hL5vUB9UrYGIIAD5EoQCaM2f', 'function': {'arguments': '{}', 'name': 'transfer_to_addition_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BpIYSqeYDDkPLrS81hasn83V7VCKR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0a38df7e-f590-4481-bbdb-e9bfa9de9684-0', tool_calls=[{'name': 'transfer_to_addition_expert', 'args': {}, 'id': 'call_hL5vUB9UrYGIIAD5EoQCaM2f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b716138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an addition expert, you can ask the multiplication expert for help with multiplication.Always do your portion of calculation before the handoff.'},\n",
       " 'can you tell me the addition of 2 and 2?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = (\n",
    "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [\"can you tell me the addition of 2 and 2?\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb312eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abf3dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Addition Expert\n",
    "def addition_agent(state: MessagesState) -> Command[Literal[\"multiplication_agent\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are an addition expert. You can ask the multiplication expert for help with multiplication. \"\n",
    "        \"Always do your portion of calculation before the handoff. \"\n",
    "        \"If the question involves both addition and multiplication, do the addition first, then transfer to multiplication expert.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    ai_msg = llm.bind_tools([transfer_to_multiplication_expert]).invoke(messages)\n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred to multiplication expert\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        \n",
    "        return Command(\n",
    "            goto=\"multiplication_agent\", \n",
    "            update={\"messages\": state[\"messages\"] + [ai_msg, tool_msg]}\n",
    "        )\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c8128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Multiplication Expert\n",
    "def multiplication_agent(state: MessagesState) -> Command[Literal[\"addition_agent\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are a multiplication expert. You can ask an addition expert for help with addition. \"\n",
    "        \"Always do your portion of calculation before the handoff. \"\n",
    "        \"If the question involves both multiplication and addition, do the multiplication, then transfer to addition expert if needed.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    ai_msg = llm.bind_tools([transfer_to_addition_expert]).invoke(messages)\n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred to addition expert\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            goto=\"addition_agent\", \n",
    "            update={\"messages\": state[\"messages\"] + [ai_msg, tool_msg]}\n",
    "        )\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc3273b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001EAAB2886E0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"addition_agent\", addition_agent)\n",
    "graph.add_node(\"multiplication_agent\", multiplication_agent)\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"addition_agent\")\n",
    "\n",
    "# Compile the app\n",
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f7f1819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the multi-agent system...\n",
      "==================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the result of (3 + 5) * 12? Then, multiply that result by 13 and provide the final answer.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Successfully transferred to multiplication expert\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_84LceqkPXRKQncqG3fYiGeyH\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      5\u001b[39m events = app.stream(\n\u001b[32m      6\u001b[39m     {\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWhat is the result of (3 + 5) * 12? Then, multiply that result by 13 and provide the final answer.\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      8\u001b[39m     },\n\u001b[32m      9\u001b[39m     stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmultiplication_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m system_prompt = (\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou are a multiplication expert. You can ask an addition expert for help with addition. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAlways do your portion of calculation before the handoff. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIf the question involves both multiplication and addition, do the multiplication, then transfer to addition expert if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt}] + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m ai_msg = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtransfer_to_addition_expert\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_msg.tool_calls) > \u001b[32m0\u001b[39m:\n\u001b[32m     14\u001b[39m     tool_call_id = ai_msg.tool_calls[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:995\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bapan Bairagya\\miniconda3\\envs\\agentic_ai\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_84LceqkPXRKQncqG3fYiGeyH\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
      "During task with name 'multiplication_agent' and id 'e6244f22-6631-1e1f-42ff-a4a90d4c6380'"
     ]
    }
   ],
   "source": [
    "# Test the system\n",
    "print(\"Testing the multi-agent system...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "events = app.stream(\n",
    "    {\n",
    "        \"messages\": [(\"user\", \"What is the result of (3 + 5) * 12? Then, multiply that result by 13 and provide the final answer.\")]\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
